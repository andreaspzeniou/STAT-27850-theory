---
title: "Simulations for Grouping E-BH, Storey and Two Step Storey E-BH"
output:
  pdf_document: default
  html_document: default
date: "2023-11-27"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyr)
```

This is the model used in our project to generate E values for simulation.

Delta is the mean from the normal distribution from which the signals are picked from. The first n e-values come from the null distribution; the next total_samples - n e-values come from the alternate distribution


```{r}
#Function that generates e_values
gen_e_val <- function(null_prop=0.2, total_samples=1000, alpha=0.1, delta=-4) {
  
  num <- total_samples
  
  number_null <- null_prop * num
  null_indices <- 1:number_null
  
  number_signal <- (1-null_prop) * num
  
  signal_indices <- number_null+1:num

  signals <- rnorm(number_signal, delta, 1)
  nulls <- rnorm(number_null, 0, 1)

  observations <- c(nulls, signals) 
  e_values <- exp(observations * delta - delta^2 / 2)
  
  return(e_values)
    
}

```

```{r}
# Function for generating certain number of null E-vals allowing for changes in delta
generate_null_eval1 <- function(num, d) {
  vect <- gen_e_val(delta = d)
  null_vect <- vect[1:200]
  random_null_entries <- sample(null_vect, num)
  return(random_null_entries)
}

# Function for generating certain numbers of signal E-vals allowing for changes in delta
generate_signal_eval1 <- function(num, d) {
  vect <- gen_e_val(delta = d)
  sig_vect <- vect[201:1000]
  random_sig_entries <- sample(sig_vect, num)
  return(random_sig_entries)
}
```

\newpage

## Testing a Group BH Procedure

```{r}
# Define Constants
n <- 1000
trials <- 100
group_num <- 20
group_size <- 50
alpha <- 0.1
```

Here, the procedure that the project runs is first creating a specific sample that comprises of null groups as well as mixed groups (nulls and signals) that are from the original function that generates E values. We have 1000 total E values, with the first 750 being from all null (groups of 50), and the last 250 being 5 groups of 50, where 25 are null and 25 are signal e values.

The base BH ignores the groups and runs e-BH, while the grouping BH takes into account the groups and uses a specific method of creating E_tildas (drawn from a Bernoulli distribution with probability 1/e), and chooses groups to keep.

Our simulation tries different delta values for E value generation to see the overall affect of grouping on power and FDR (while delta values are varied)

We then plot this as our results. We use 100 trials for each delta value and take the average as a measurement of FDR and power.

```{r}
# Comparison of Base e-BH vs. Grouping e-BH
# Graphing FDR and Power for Various Deltas for both methods

delta_trials <- seq(-6, -0.25, by = 0.25)
avg_fdr_nongroup <- c()
avg_power_nongroup <- c()
avg_fdr_group <- c()
avg_power_group <- c()

# Method 1 - Non Grouping

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_vect <- c()
  power_vect <- c()
  
  #Running Trials
  for (k in 1:trials) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      if (i <= 15) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        for (i in 1:group_size) {
          if (i %% 2 == 0) {
            # Even indices: null e vals
            full_group[i] <- generate_null_eval1(1, del)
          } else {
            # Odd indices: signal e vals
            full_group[i] <- generate_signal_eval1(1, del)
          }
        }
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running BH on the entire set of 1000 e-values, ignoring the groups
    converted_evals <- 1/vect_evals
    adjusted_converted_evals <- p.adjust(converted_evals, method = "BH")
    signal_indices <- which(adjusted_converted_evals < alpha)
    
    # Calculating FDR
    total_discoveries <- length(signal_indices)
    true_discoveries <- sum(signal_indices > 750 & signal_indices < 1000 & signal_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR <- 1 - fdr_ratio
    FDR_vect <- c(FDR_vect, FDR)
    
    # Calculating Power
    total_signals <- 125
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power <- 1 - power_ratio
    power_vect <- c(power_vect, power)
    
  }

  avg_fdr_nongroup <- c(avg_fdr_nongroup, mean(FDR_vect))
  avg_power_nongroup <- c(avg_power_nongroup, mean(power_vect))
  
}

```

\newpage

```{r}
# Method 2 - Grouping

for (del in delta_trials) {

  # Shells for Trials
  FDR_vect_new <- c()
  power_vect_new <- c()
  
  for (k in 1:trials) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      if (i <= 15) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        for (i in 1:group_size) {
          if (i %% 2 == 0) {
            # Even indices: null evals
            full_group[i] <- generate_null_eval1(1, del)
          } else {
            # Odd indices: signal evals
            full_group[i] <- generate_signal_eval1(1, del)
          }
        }
        full_group[full_group < 1] <- 1
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Figuring out which groups to keep
    kept_groups <- c()
    
    for (i in 1:group_num) {
      e_tildas <- c()
      current_evals <- unlist(list_evals[i])
      for (e in current_evals) {
        if (e < 1) {
          prob_e <- 1
        } else {
          prob_e <- 1/e
        }
        e_t <- rbinom(1, size = 1, prob = prob_e)
        e_tildas <- c(e_tildas, e_t)
      }
      count_zeroes <- sum(e_tildas == 0)
      if (count_zeroes >= 20) {
        kept_groups <- c(kept_groups, TRUE)
      } else {
        kept_groups <- c(kept_groups, FALSE)
      }
    }
    
    kept_groups_indices <- which(kept_groups)
    
    # Running e_BH on remaining data
    kept_evals <- list_evals[kept_groups_indices]
    new_n <- length(kept_groups_indices) * group_size
    n_null_groups <- sum(kept_groups_indices < 16) * group_size
    
    kept_evals_vect <- unlist(kept_evals)
    kept_converted_evals_vect <- 1/kept_evals_vect
    kept_adjusted_converted_evals <- p.adjust(kept_converted_evals_vect, method = "BH")
    kept_signal_indices <- which(kept_adjusted_converted_evals < alpha)
    
    # Calculating FDR and Power
    kept_total_discoveries <- length(kept_signal_indices)
    kept_true_discoveries <- sum(kept_signal_indices > n_null_groups & 
                                   kept_signal_indices < new_n & kept_signal_indices %% 2 == 1)
    ratio_fdr <- kept_true_discoveries/kept_total_discoveries
    if (is.nan(ratio_fdr)) {
      ratio_fdr <- 1
    }
    kept_FDR <- 1 - ratio_fdr
    FDR_vect_new <- c(FDR_vect_new, kept_FDR)
    
    # Calculating Power
    kept_total_signals <- (new_n - n_null_groups) / 2
    ratio_power <- (kept_total_signals - kept_true_discoveries) /kept_total_signals
    if (is.nan(ratio_power)) {
      ratio_power <- 1
    }
    kept_power <- 1 - ratio_power
    power_vect_new <- c(power_vect_new, kept_power)
    
  }
  
  avg_fdr_group <- c(avg_fdr_group, mean(FDR_vect_new))
  avg_power_group <- c(avg_power_group, mean(power_vect_new))

}

```

\newpage

## Results

```{r}
# Graphing FDR for Grouping vs. Non Grouping E BH
data <- data.frame(delta_trials, avg_fdr_nongroup, avg_fdr_group)
ggplot(data, aes(x = delta_trials)) +
  geom_line(aes(y = avg_fdr_nongroup), color = "blue", linetype = "solid", size = 1) +
  geom_line(aes(y = avg_fdr_group), color = "red", linetype = "solid", size = 1) +
  
  geom_text(aes(x = max(delta_trials), y = max(avg_fdr_nongroup), label = "Base-eBH"), 
            hjust = 1, vjust = 1, color = "blue") +
  geom_text(aes(x = max(delta_trials), y = max(avg_fdr_group), label = "Grouping-eBH"), 
            hjust = 1, vjust = -0.5, color = "red") +
  
  labs(title = "Comparing FDR of Grouping vs. Non Grouping",
       x = "Delta Values",
       y = "Average FDR Across Trials") +
  
  theme_minimal()
```

```{r}
# Graphing Power for Grouping vs. Non Grouping E BH
data <- data.frame(delta_trials, avg_power_nongroup, avg_power_group)
ggplot(data, aes(x = delta_trials)) +
  geom_line(aes(y = avg_power_nongroup), color = "blue", linetype = "solid", size = 1) +
  geom_line(aes(y = avg_power_group), color = "red", linetype = "solid", size = 1) +
  
  geom_text(aes(x = max(delta_trials), y = max(avg_power_nongroup), label = "Base-eBH"), 
            hjust = 1, vjust = 1, color = "blue") +
  geom_text(aes(x = max(delta_trials), y = max(avg_power_group), label = "Grouping-eBH"), 
            hjust = 1, vjust = -0.5, color = "red") +
  
  labs(title = "Comparing Power of Grouping vs. Non Grouping",
       x = "Delta Values",
       y = "Average Power Across Trials") +
  
  theme_minimal()
```

\newpage

## Storey E-BH and Two Step Storey E-BH

Here, we are utilizing the same sample, but comparing Storey E-BH and Two Step Storey E-BH with the base E-BH model. We are changing our sample to where now, we have 500 values that are signals, and 500 null values. We again compare power and FDR for Storey E-BH and Two Step Storey E-BH with the base E-BH method.

```{r}
# Method 3 - Non Grouping with Storey-e-BH
e_bh_storey <- function(TE,alpha){
  p_vals_adjusted <- p.adjust(1 / TE, method = "BH")
  rejected_indices <- which(p_vals_adjusted <= alpha)
  return(rejected_indices)
}
```

```{r}
gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      if (i <= 15) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        for (i in 1:group_size) {
          if (i %% 2 == 0) {
            # Even indices: null e vals
            full_group[i] <- generate_null_eval1(1, del)
          } else {
            # Odd indices: signal e vals
            full_group[i] <- generate_signal_eval1(1, del)
          }
        }
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 10
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 750 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 125
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 750 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 125
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  
}
```

```{r}
gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      # Putting every group as mixed group here
      if (i <= -1) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        for (i in 1:group_size) {
          if (i %% 2 == 0) {
            # Even indices: null e vals
            full_group[i] <- generate_null_eval1(1, del)
          } else {
            # Odd indices: signal e vals
            full_group[i] <- generate_signal_eval1(1, del)
          }
        }
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 100
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 0 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 0 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  
}
```



\newpage

## Results

```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_power_nongroup = avg_power_nongroup,
  avg_power_storey = avg_power_storey,
  avg_power_twostp_storey = avg_power_twostp_storey
)

data_long <- tidyr::gather(data, key = "Group", value = "Power", -delta_trials)

ggplot(data_long, aes(x = delta_trials, y = Power, color = Group)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "Average Power",
    color = "Different Tests",
    title = "Comparison of Average Power"
  ) +
  scale_color_discrete(labels = c(
    "avg_power_nongroup" = "Base E-BH",
    "avg_power_storey" = "Storey E-BH",
    "avg_power_twostp_storey" = "Two Step Storey E-BH"
  ))

```

```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_fdr_nongroup = avg_fdr_nongroup,
  avg_fdr_storey = avg_fdr_storey,
  avg_fdr_twostp_storey = avg_fdr_twostp_storey
)

data <- tidyr::gather(data, key = "variable", value = "value", -delta_trials)

ggplot(data, aes(x = delta_trials, y = value, color = variable)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "FDR Values",
    color = "Different Tests",
    title = "Comparison of Average FDR"
  ) +
  scale_color_discrete(labels = c(
    "avg_fdr_nongroup" = "Base E-BH",
    "avg_fdr_storey" = "Storey E-BH",
    "avg_fdr_twostp_storey" = "Two Step Storey E-BH"))

```

\newpage

## Base e-BH and all three Storey e-BH proposed methods

Now, we are going to see how these two Storey methods compare to the "natural" version of Storey e-BH where one converts e values to p values straight away and runs Storey BH on the resulting p values. 

```{r}
e_Storey_BH_natural <- function(e_vals, alpha, gam){
  p_vals <- convert_e_vals_to_p_vals(e_vals)
  m <- length(p_vals)
  num_p_vals_greater_than_gamma <- length(p_vals[p_vals > gam])
  pi_0_hat <- (num_p_vals_greater_than_gamma + 1) / (m * (1 - gam))
  p_vals <- convert_e_vals_to_p_vals(e_vals)
  return(BH(p_vals = p_vals, alpha = alpha / pi_0_hat))
}
```


```{r}
gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_fdr_natural_storey <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()
avg_power_natural_storey <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  FDR_natural_storey_vect <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  power_natural_storey_vect <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      # Putting every group as mixed group here
      if (i <= -1) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        for (i in 1:group_size) {
          if (i %% 2 == 0) {
            # Even indices: null e vals
            full_group[i] <- generate_null_eval1(1, del)
          } else {
            # Odd indices: signal e vals
            full_group[i] <- generate_signal_eval1(1, del)
          }
        }
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 100
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # running the natural Storey e-BH function with gamma = .5
    natural_storey_indices <- e_Storey_BH_natural(vect_evals, alpha, .5)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 0 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 0 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
    # Calculating FDR for Natural Storey
    
    total_discoveries <- length(natural_storey_indices)
    true_discoveries <- sum(natural_storey_indices > 0 & natural_storey_indices < 1000 & natural_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_natural_storey <- 1 - fdr_ratio
    FDR_natural_storey_vect <- c(FDR_natural_storey_vect, FDR_natural_storey)
    
    # Calculating Power for Natural Storey
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_natural_storey <- 1 - power_ratio
    power_natural_storey_vect <- c(power_natural_storey_vect, power_natural_storey)
    
    
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_fdr_natural_storey <- c(avg_fdr_natural_storey, mean(FDR_natural_storey_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  avg_power_natural_storey <- c(avg_power_natural_storey, mean(power_natural_storey_vect))
  
}
```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_power_nongroup = avg_power_nongroup,
  avg_power_storey = avg_power_storey,
  avg_power_twostp_storey = avg_power_twostp_storey,
  avg_power_natural_storey = avg_power_natural_storey
)

data_long <- tidyr::gather(data, key = "Group", value = "Power", -delta_trials)

ggplot(data_long, aes(x = delta_trials, y = Power, color = Group)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "Average Power",
    color = "Different Tests",
    title = "Comparison of Average Power"
  ) +
  scale_color_discrete(labels = c(
    "avg_power_nongroup" = "Base E-BH",
    "avg_power_storey" = "Storey E-BH",
    "avg_power_twostp_storey" = "Two Step Storey E-BH",
    "avg_power_natural_storey" = "Natural Storey E-BH"
  ))

```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_fdr_nongroup = avg_fdr_nongroup,
  avg_fdr_storey = avg_fdr_storey,
  avg_fdr_twostp_storey = avg_fdr_twostp_storey,
  avg_fdr_natural_storey = avg_fdr_natural_storey
)

data <- tidyr::gather(data, key = "variable", value = "value", -delta_trials)

ggplot(data, aes(x = delta_trials, y = value, color = variable)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "FDR Values",
    color = "Different Tests",
    title = "Comparison of Average FDR"
  ) +
  scale_color_discrete(labels = c(
    "avg_fdr_nongroup" = "Base E-BH",
    "avg_fdr_storey" = "Storey E-BH",
    "avg_fdr_twostp_storey" = "Two Step Storey E-BH", 
    "avg_fdr_natural_storey" = "Natural Storey E-BH"))

```

\newpage


## Testing the previous methods under dependence


```{r}
# a different method for generating e values where you add a chi square to the signal X_ks
gen_e_val2 <- function(null_prop=0.2, total_samples=1000, alpha=0.1, delta=-4) {
  
  num <- total_samples
  
  number_null <- null_prop * num
  null_indices <- 1:number_null
  
  number_signal <- (1-null_prop) * num
  
  signal_indices <- number_null+1:num

  signals <- rnorm(number_signal, delta, 1) - rchisq(number_signal, df = 1)
  nulls <- rnorm(number_null, 0, 1)

  observations <- c(nulls, signals) 
  e_values <- exp(observations * delta - delta^2 / 2)
  
  return(e_values)
    
}

```

```{r}
# generate a signal e value with this new function
generate_signal_eval2 <- function(num, d) {
  vect <- gen_e_val2(delta = d)
  sig_vect <- vect[201:1000]
  random_sig_entries <- sample(sig_vect, num)
  return(random_sig_entries)
}
```

```{r}
generate_signal_null_eval_pair <- function(delta, df){
  # generate a null then a signal X_k value used in generating e values where the signal X_k is dependent on the null X_k by subtracting a chi square from the null X_k
  # delta is the parameter of the likelihood ratio-type statistic, df is the parameter of the degrees of freedom used in the chi square distribution
  null_xk <- rnorm(1)
  signal_xk <- null_xk - rchisq(1, df)
  observations <- c(signal_xk, null_xk)
  e_values <- exp(observations * delta - delta^2 / 2)
  return(e_values)
}
```





```{r}
# THIS EXAMPLE IS EITHER BROKEN OR IS ABLE TO SOMEHOW BREAK STOREY BH - GIVES NO POWER TO STOREY
gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_fdr_natural_storey <- c()
avg_fdr_base_ebh <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()
avg_power_natural_storey <- c()
avg_power_base_ebh <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  FDR_natural_storey_vect <- c()
  FDR_base_ebh <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  power_natural_storey_vect <- c()
  power_base_ebh <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      # Putting every group as mixed group here
      if (i <= -1) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        # for signal groups, only the first e value of the group will be generated independently
        for (j in 1:group_size) {
          if (j == 1){
            full_group[j] <- generate_signal_eval1(1, del)
          }
          else if (j %% 2 == 0) {
            # Even indices: null e vals
            full_group[j] <- generate_null_eval1(1, del)
          }
          else {
            # Odd indices > 1: X_ks for signal e vals are generated by the null e value that came before it combined with a chi square random
            full_group[j] <- full_group[j-1] + rchisq(1, df = 8)
          }
        }
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 100
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # running the natural Storey e-BH function with gamma = .5
    natural_storey_indices <- e_Storey_BH_natural(vect_evals, alpha, .5)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 0 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 0 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
    # Calculating FDR for Natural Storey
    
    total_discoveries <- length(natural_storey_indices)
    true_discoveries <- sum(natural_storey_indices > 0 & natural_storey_indices < 1000 & natural_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_natural_storey <- 1 - fdr_ratio
    FDR_natural_storey_vect <- c(FDR_natural_storey_vect, FDR_natural_storey)
    
    # Calculating Power for Natural Storey
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_natural_storey <- 1 - power_ratio
    power_natural_storey_vect <- c(power_natural_storey_vect, power_natural_storey)
    
    # calculating FDR for base e BH
    
    total_discoveries <- length(base_ebh_indices)
    true_discoveries <- sum(base_ebh_indices > 0 & base_ebh_indices < 1000 & base_ebh_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_base_ebh <- 1 - fdr_ratio
    FDR_base_ebh_vect <- c(FDR_base_ebh_vect, FDR_base_ebh)
    
    # calculating power for base e BH
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_base_ebh <- 1 - power_ratio
    power_base_ebh_vect <- c(power_base_ebh_vect, power_base_ebh)
    
    
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_fdr_natural_storey <- c(avg_fdr_natural_storey, mean(FDR_natural_storey_vect))
  avg_fdr_base_ebh <- c(avg_fdr_base_ebh, mean(FDR_base_ebh_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  avg_power_natural_storey <- c(avg_power_natural_storey, mean(power_natural_storey_vect))
  avg_power_base_ebh <- c(avg_power_base_ebh, mean(power_base_ebh_vect))
  
}
```

## Results for dependence test 1

```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_power_base_ebh = avg_power_base_ebh,
  avg_power_storey = avg_power_storey,
  avg_power_twostp_storey = avg_power_twostp_storey,
  avg_power_natural_storey = avg_power_natural_storey
)

data_long <- tidyr::gather(data, key = "Group", value = "Power", -delta_trials)

ggplot(data_long, aes(x = delta_trials, y = Power, color = Group)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "Average Power",
    color = "Different Tests",
    title = "Comparison of Average Power"
  ) +
  scale_color_discrete(labels = c(
    "avg_power_base_ebh" = "Base E-BH",
    "avg_power_storey" = "Storey E-BH",
    "avg_power_twostp_storey" = "Two Step Storey E-BH",
    "avg_power_natural_storey" = "Natural Storey E-BH"
  ))

```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_fdr_base_ebh = avg_fdr_base_ebh,
  avg_fdr_storey = avg_fdr_storey,
  avg_fdr_twostp_storey = avg_fdr_twostp_storey,
  avg_fdr_natural_storey = avg_fdr_natural_storey
)

data <- tidyr::gather(data, key = "variable", value = "value", -delta_trials)

ggplot(data, aes(x = delta_trials, y = value, color = variable)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "FDR Values",
    color = "Different Tests",
    title = "Comparison of Average FDR"
  ) +
  scale_color_discrete(labels = c(
    "avg_fdr_base_ebh" = "Base E-BH",
    "avg_fdr_storey" = "Storey E-BH",
    "avg_fdr_twostp_storey" = "Two Step Storey E-BH", 
    "avg_fdr_natural_storey" = "Natural Storey E-BH"))

```

\newpage 

## Dependence test 2 - making dependence between the X_ks to generate dependent e values


```{r}

gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_fdr_natural_storey <- c()
avg_fdr_base_ebh <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()
avg_power_natural_storey <- c()
avg_power_base_ebh <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  FDR_natural_storey_vect <- c()
  FDR_base_ebh_vect <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  power_natural_storey_vect <- c()
  power_base_ebh_vect <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      # Putting every group as mixed group here
      if (i <= -1) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        # only the last e value of the group will be generated independently, and the middle elements will be generated in dependent pairs where the signal is dependent on the null
  
        for (j in seq(from = 1, to = 19, by = 2)) {
          # Create dependent null, signal pair using the function above
          full_group[j:(j+1)] <- generate_signal_null_eval_pair(delta = del, df = 3) # subtracting a chisquare with degree of freedom 3
        }
        full_group[20] <- generate_null_eval1(1, del)
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 100
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # running the natural Storey e-BH function with gamma = .5
    natural_storey_indices <- e_Storey_BH_natural(vect_evals, alpha, .5)
    
    # running the base e BH
    
    base_ebh_indices <- e_BH(vect_evals, alpha)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 0 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 0 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
    # Calculating FDR for Natural Storey
    
    total_discoveries <- length(natural_storey_indices)
    true_discoveries <- sum(natural_storey_indices > 0 & natural_storey_indices < 1000 & natural_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_natural_storey <- 1 - fdr_ratio
    FDR_natural_storey_vect <- c(FDR_natural_storey_vect, FDR_natural_storey)
    
    # Calculating Power for Natural Storey
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_natural_storey <- 1 - power_ratio
    power_natural_storey_vect <- c(power_natural_storey_vect, power_natural_storey)
    
    # calculating FDR for base e BH
    
    total_discoveries <- length(base_ebh_indices)
    true_discoveries <- sum(base_ebh_indices > 0 & base_ebh_indices < 1000 & base_ebh_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_base_ebh <- 1 - fdr_ratio
    FDR_base_ebh_vect <- c(FDR_base_ebh_vect, FDR_base_ebh)
    
    # calculating power for base e BH
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_base_ebh <- 1 - power_ratio
    power_base_ebh_vect <- c(power_base_ebh_vect, power_base_ebh)
    
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_fdr_natural_storey <- c(avg_fdr_natural_storey, mean(FDR_natural_storey_vect))
  avg_fdr_base_ebh <- c(avg_fdr_base_ebh, mean(FDR_base_ebh_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  avg_power_natural_storey <- c(avg_power_natural_storey, mean(power_natural_storey_vect))
  avg_power_base_ebh <- c(avg_power_base_ebh, mean(power_base_ebh_vect))
}
```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_power_base_ebh = avg_power_base_ebh,
  avg_power_storey = avg_power_storey,
  avg_power_twostp_storey = avg_power_twostp_storey,
  avg_power_natural_storey = avg_power_natural_storey
)

data_long <- tidyr::gather(data, key = "Group", value = "Power", -delta_trials)

ggplot(data_long, aes(x = delta_trials, y = Power, color = Group)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "Average Power",
    color = "Different Tests",
    title = "Comparison of Average Power"
  ) +
  scale_color_discrete(labels = c(
    "avg_power_base_ebh" = "Base E-BH",
    "avg_power_storey" = "Storey E-BH",
    "avg_power_twostp_storey" = "Two Step Storey E-BH",
    "avg_power_natural_storey" = "Natural Storey E-BH"
  ))

```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_fdr_base_ebh = avg_fdr_base_ebh,
  avg_fdr_storey = avg_fdr_storey,
  avg_fdr_twostp_storey = avg_fdr_twostp_storey,
  avg_fdr_natural_storey = avg_fdr_natural_storey
)

data <- tidyr::gather(data, key = "variable", value = "value", -delta_trials)

ggplot(data, aes(x = delta_trials, y = value, color = variable)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "FDR Values",
    color = "Different Tests",
    title = "Comparison of Average FDR"
  ) +
  scale_color_discrete(labels = c(
    "avg_fdr_base_ebh" = "Base E-BH",
    "avg_fdr_storey" = "Storey E-BH",
    "avg_fdr_twostp_storey" = "Two Step Storey E-BH", 
    "avg_fdr_natural_storey" = "Natural Storey E-BH"))

```

## Dependence test 3

```{r}

gam <- 0
alpha_storey <- 0.1
avg_fdr_storey <- c()
avg_fdr_twostp_storey <- c()
avg_fdr_natural_storey <- c()
avg_fdr_base_ebh <- c()
avg_power_storey <- c()
avg_power_twostp_storey <- c()
avg_power_natural_storey <- c()
avg_power_base_ebh <- c()

for (del in delta_trials) {
  
  # Shells for Trials
  FDR_storey_vect <- c()
  FDR_twostp_storey_vect <- c()
  FDR_natural_storey_vect <- c()
  FDR_base_ebh <- c()
  power_storey_vect <- c()
  power_twostp_storey_vect <- c()
  power_natural_storey_vect <- c()
  power_base_ebh <- c()
  
  #Running Trials
  for (k in 1:trials*10) {
    # Create sample
    
    list_evals <- list()
    
    for (i in 1:group_num) {
      # Putting every group as mixed group here
      if (i <= -1) {
        nulls <- generate_null_eval1(50, del)
        list_evals <- append(list_evals, list(nulls))
      } else {
        full_group <- numeric(group_size)
        # only the last e value of the group will be generated independently, and the middle elements will be generated in dependent pairs where the signal is dependent on the null
        full_group[1] <- generate_signal_eval1(1, del)
        for (j in 2:20) {
          # Create dependent null, signal pair using the function above
          if (j %% 2 == 0){
            # even index - null e value
            full_group[j] <- generate_null_eval1(1, del)
          }
          else{
            # odd index - signal e value which is dependent on the previous signal
            full_group[j] <- full_group[j-2]- rchisq(1, df = 1)
          }
          
        }
        
        list_evals <- append(list_evals, list(full_group))
      }
    }
    
    vect_evals <- unlist(list_evals)
    
    # Running Storey-E-BH on the entire set of 1000 e-values, ignoring the groups
    sorted_e_values <- sort(vect_evals)
    khat <- 0
    for (k2 in (1:length(sorted_e_values))) {
      first <- sorted_e_values[1:k2]
      if (mean(first) <= 1 + gam) {
        khat <- k2
      } else {
        break
      }
    }
    pi_0_hat <- (1 + khat) / length(sorted_e_values)
    beta <- alpha_storey / 100
    N_e_vals <- length(sorted_e_values)
    khat2 <- length(sorted_e_values[1/sorted_e_values > beta / N_e_vals])
    pi_0_hat2 <- (khat2) / length(sorted_e_values)
    
    storey_indices <- e_bh_storey(vect_evals, alpha_storey/ pi_0_hat)
    
    two_step_storey_indices <- e_bh_storey(vect_evals,(alpha_storey - beta) / pi_0_hat2)
    
    # running the natural Storey e-BH function with gamma = .5
    natural_storey_indices <- e_Storey_BH_natural(vect_evals, alpha, .5)
    
    # Calculating FDR for Storey
    total_discoveries <- length(storey_indices)
    true_discoveries <- sum(storey_indices > 0 & storey_indices < 1000 & storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_storey <- 1 - fdr_ratio
    FDR_storey_vect <- c(FDR_storey_vect, FDR_storey)
    
    # Calculating Power for Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_storey <- 1 - power_ratio
    power_storey_vect <- c(power_storey_vect, power_storey)
    
    # Calculating FDR for Two Step Storey
    total_discoveries <- length(two_step_storey_indices)
    true_discoveries <- sum(two_step_storey_indices > 0 & two_step_storey_indices < 1000 & two_step_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_twostp_storey <- 1 - fdr_ratio
    FDR_twostp_storey_vect <- c(FDR_twostp_storey_vect, FDR_twostp_storey)
    
    # Calculating Power for Two Step Storey
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_twostp_storey <- 1 - power_ratio
    power_twostp_storey_vect <- c(power_twostp_storey_vect, power_twostp_storey)
    
    # Calculating FDR for Natural Storey
    
    total_discoveries <- length(natural_storey_indices)
    true_discoveries <- sum(natural_storey_indices > 0 & natural_storey_indices < 1000 & natural_storey_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_natural_storey <- 1 - fdr_ratio
    FDR_natural_storey_vect <- c(FDR_natural_storey_vect, FDR_natural_storey)
    
    # Calculating Power for Natural Storey
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_natural_storey <- 1 - power_ratio
    power_natural_storey_vect <- c(power_natural_storey_vect, power_natural_storey)
    
     # calculating FDR for base e BH
    
    total_discoveries <- length(base_ebh_indices)
    true_discoveries <- sum(base_ebh_indices > 0 & base_ebh_indices < 1000 & base_ebh_indices %% 2 == 1)
    fdr_ratio <- true_discoveries/total_discoveries
    if (is.nan(fdr_ratio)) {
      fdr_ratio <- 1
    }
    FDR_base_ebh <- 1 - fdr_ratio
    FDR_base_ebh_vect <- c(FDR_base_ebh_vect, FDR_base_ebh)
    
    # calculating power for base e BH
    
    total_signals <- 500
    power_ratio <- (total_signals - true_discoveries) / total_signals
    if (is.nan(power_ratio)) {
      power_ratio <- 1
    }
    power_base_ebh <- 1 - power_ratio
    power_base_ebh_vect <- c(power_base_ebh_vect, power_base_ebh)
    
  }
  
  avg_fdr_storey <- c(avg_fdr_storey, mean(FDR_storey_vect))
  avg_fdr_twostp_storey <- c(avg_fdr_twostp_storey, mean(FDR_twostp_storey_vect))
  avg_fdr_natural_storey <- c(avg_fdr_natural_storey, mean(FDR_natural_storey_vect))
  avg_fdr_base_ebh <- c(avg_fdr_base_ebh, mean(FDR_base_ebh_vect))
  avg_power_storey <- c(avg_power_storey, mean(power_storey_vect))
  avg_power_twostp_storey <- c(avg_power_twostp_storey, mean(power_twostp_storey_vect))
  avg_power_natural_storey <- c(avg_power_natural_storey, mean(power_natural_storey_vect))
  avg_power_base_ebh <- c(avg_power_base_ebh, mean(power_base_ebh_vect))
  
}
```

```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_power_base_ebh = avg_power_base_ebh,
  avg_power_storey = avg_power_storey,
  avg_power_twostp_storey = avg_power_twostp_storey,
  avg_power_natural_storey = avg_power_natural_storey
)

data_long <- tidyr::gather(data, key = "Group", value = "Power", -delta_trials)

ggplot(data_long, aes(x = delta_trials, y = Power, color = Group)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "Average Power",
    color = "Different Tests",
    title = "Comparison of Average Power"
  ) +
  scale_color_discrete(labels = c(
    "avg_power_base_ebh" = "Base E-BH",
    "avg_power_storey" = "Storey E-BH",
    "avg_power_twostp_storey" = "Two Step Storey E-BH",
    "avg_power_natural_storey" = "Natural Storey E-BH"
  ))

```


```{r}
data <- data.frame(
  delta_trials = delta_trials,
  avg_fdr_base_ebh = avg_fdr_base_ebh,
  avg_fdr_storey = avg_fdr_storey,
  avg_fdr_twostp_storey = avg_fdr_twostp_storey,
  avg_fdr_natural_storey = avg_fdr_natural_storey
)

data <- tidyr::gather(data, key = "variable", value = "value", -delta_trials)

ggplot(data, aes(x = delta_trials, y = value, color = variable)) +
  geom_line() +
  labs(
    x = "Delta for E Value Generation",
    y = "FDR Values",
    color = "Different Tests",
    title = "Comparison of Average FDR"
  ) +
  scale_color_discrete(labels = c(
    "avg_fdr_base_ebh" = "Base E-BH",
    "avg_fdr_storey" = "Storey E-BH",
    "avg_fdr_twostp_storey" = "Two Step Storey E-BH", 
    "avg_fdr_natural_storey" = "Natural Storey E-BH"))

```

